{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import textblob\n",
    "from gensim.models import word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels import robust\n",
    "from string import punctuation\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import keras\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# for mac only: frog,blow,funk,glass,tink,submarine,purr,sosumi\n",
    "def beep(audio): \n",
    "    os.system('afplay /System/Library/Sounds/' + audio +'.aiff')\n",
    "    os.system('afplay /System/Library/Sounds/' + audio +'.aiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:62654\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:62654' processes=4 cores=4>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(n_workers=4, threads_per_worker=1, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = dd.read_csv('boardgame-comments-english.csv').sample(frac=.1,random_state=42)\n",
    "review = client.persist(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Comments: 84165\n"
     ]
    }
   ],
   "source": [
    "review.columns = 'reviewer_id', 'game_id', 'rating', 'comment'\n",
    "\n",
    "# RATINGS ADJUSTMENT: ceiling >= .5 [or] floor < .5\n",
    "ratings = da.array(review.rating.round()).compute()\n",
    "\n",
    "print('Total Comments: {}'.format(len(review.comment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 247 ms, total: 1.68 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = da.array(review.comment.apply(lambda val: [b.lower() for b in textblob.TextBlob(val).words])).compute()\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 s, sys: 326 ms, total: 53.1 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    # # load model\n",
    "    word_vec = word2vec.Word2Vec.load('full_word2vec_blob.bin')\n",
    "    vec_size = word_vec.layer1_size\n",
    "else: \n",
    "    vec_size = 50\n",
    "    word_vec = word2vec.Word2Vec(\n",
    "        sentences,\n",
    "        workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "        min_count=5,  # Minimum word count threshold.\n",
    "        window=6,      # Number of words around target word to consider.\n",
    "        sg=0,          # Use CBOW because our corpus is small.\n",
    "        sample=1e-3 ,  # Penalize frequent words.\n",
    "        size=vec_size,      # Word vector length.\n",
    "        hs=1           # Use hierarchical softmax.\n",
    "    )\n",
    "    \n",
    "    # save model\n",
    "    word_vec.save('full_word2vec_blob.bin')\n",
    "\n",
    "# List of words in model.\n",
    "vocab = word_vec.wv.vocab.keys()\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.2 ms, sys: 14.6 ms, total: 112 ms\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec_new = np.array([.5 for i in range(0,vec_size)])\n",
    "vectors = da.array(map(lambda val: [word_vec[w] if w in vocab else vec_new for w in val], sentences))\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1-1', 0.6517734527587891)]\n",
      "[('map', 0.6931158900260925), ('intent', 0.6568892598152161), ('gameboard', 0.6398290395736694)]\n",
      "[('difficult', 0.8791060447692871), ('easy', 0.7894079089164734), ('tough', 0.720523476600647)]\n"
     ]
    }
   ],
   "source": [
    "w1,w2,w3 = 'gamer','player','game'\n",
    "print(word_vec.most_similar(positive=[w1, w2], negative=[w3], topn=1))\n",
    "\n",
    "w1 = 'board'\n",
    "print(word_vec.wv.most_similar(positive=w1,topn=3))\n",
    "\n",
    "w1 = 'hard'\n",
    "print(word_vec.wv.most_similar(positive=w1,topn=3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "with joblib.parallel_backend('dask', scatter=[X, y]):\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'cos similarity' on two word vectors [cosine of the angle is measure of similarity']\n",
    "\n",
    "'diff' = [300x]\n",
    "'hard' = [300x]\n",
    "'cat' = [300x]\n",
    "\n",
    "np.dot('diff','hard') / len(diff)\n",
    "'cosine similarity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Comprehensive Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 303 ms, total: 16.2 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pad, max_words = np.array([0 for i in range(0,vec_size)]), 30\n",
    "\n",
    "def manual_pad(val):\n",
    "    empty = max_words-len(val)\n",
    "    for i in range(0,empty):\n",
    "        val.append(pad)\n",
    "    \n",
    "    return [i for i in val[0:max_words]]\n",
    "\n",
    "vectors_padding = list(map(manual_pad,vectors))\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 s, sys: 139 ms, total: 1.66 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = np.array(ratings).astype(int).ravel()\n",
    "X = pd.DataFrame([list(i[0]) for i in vectors_padding])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _A - Logistic Regression w/ Vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for overfitting:\n",
      "30.205710232310697\n",
      "\n",
      "Percentage of ratings guessed correctly:\n",
      "29.836183618361833\n"
     ]
    }
   ],
   "source": [
    "print('Check for overfitting:')\n",
    "print(lr.score(X_train,y_train)*100)\n",
    "print('')\n",
    "# Print Model Score Estimation on Same Data\n",
    "print('Percentage of ratings guessed correctly:')\n",
    "print(lr.score(X_test,y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _B - MLP Neural NN w/ Vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29447344734473446"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _C - Keras Sequential NN_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.ravel()\n",
    "y_train = y_train.ravel()\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84165"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(vec_size,max_words)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(11, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "beep('ping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.943898053109163\n",
      "Test accuracy: 0.29274527451350385\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity Visualization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X = word_vec[word_vec.wv.vocab]\n",
    "graph_tsne = TSNE(n_components=2)\n",
    "result = graph_tsne.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(word_vec.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "# plt.ylim(-0.006,0.008)\n",
    "# plt.xlim(-.02,.04)\n",
    "plt.show()\n",
    "\n",
    "graph_pca = PCA(n_components=2)\n",
    "result = graph_pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(word_vec.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "# plt.ylim(-0.006,0.008)\n",
    "# plt.xlim(-.02,.04)\n",
    "plt.show()\n",
    "beep('ping')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
